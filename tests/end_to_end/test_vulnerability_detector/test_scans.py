import argparse
import base64
import os
import re
import subprocess
import tempfile
from multiprocessing.pool import ThreadPool

import pytest
import ansible_runner
import xml.dom.minidom
import yaml
from ansible.inventory.manager import InventoryManager
from ansible.parsing.dataloader import DataLoader

from wazuh_testing.tools.configuration import (
    load_configuration_template, set_section_wazuh_conf
)
from wazuh_testing.tools.monitoring import HostMonitor
from wazuh_testing.tools.system import HostManager
from wazuh_testing.api import make_api_call, get_token_login_api
from wazuh_testing.end_to_end import get_alert_indexer_api

current_dir = os.path.dirname(__file__)
configurations_dir = os.path.join(current_dir, "data", "configurations")
cases = {}
local_path = os.path.dirname(os.path.abspath(__file__))
tmp_path = os.path.join(local_path, 'tmp')
regex_path = os.path.join(current_dir, 'data', 'regex.yaml')
STATE_INDEX_NAME = 'agents_state_index'


with open(os.path.join(current_dir, 'cases.yaml'), 'r') as cases_file:
    cases = yaml.load(cases_file, Loader=yaml.FullLoader)

configurations_paths = {
    'manager': os.path.join(configurations_dir, 'manager.yaml'),
    'agent': os.path.join(configurations_dir, 'agent.yaml')
}

configuration_filepath_os = {
    'linux': '/var/ossec/etc/ossec.conf',
    'windows': 'C:\Program Files (x86)\ossec-agent\ossec.conf',
    'macos': '/Library/Ossec/etc/ossec.conf'
}
logs_filepath_os = {
    'linux': '/var/ossec/logs/ossec.log',
    'windows': 'C:\Program Files (x86)\ossec-agent\ossec.log',
    'macos': '/Library/Ossec/logs/ossec.log'
}



complete_list = [ (case['preconditions'], case['body'], case['teardown']) for case in cases]
dependencies = [None if 'depends' not in case else pytest.mark.depends(name=case['depend']) for case in cases]
list_ids = [ case['id'] for case in cases]



@pytest.fixture(scope='module')
def setup_vulnerability_tests(host_manager):
    # Configure managers and agents
    hosts_configuration_backup = backup_configurations(host_manager)
    configure_environment_manager(host_manager, load_vulnerability_detector_configurations())

    # Restart managers and stop agents
    control_environment(host_manager, 'stop', ['agent'])
    control_environment(host_manager, 'restart', ['manager'])

    # Wait until VD is updated
    wait_until_vd_is_updated(host_manager)

    # Truncate alerts and logs of managers and agents
    truncate_logs(host_manager)

    # Start agents
    control_environment(host_manager, 'start', ['agent'])

    yield

    restore_backup(host_manager, hosts_configuration_backup)

def backup_configurations(host_manager):
    backup_configurations = {}
    for host in host_manager.get_group_hosts('all'):
        host_variables = host_manager.get_host_variables(host)
        host_os = host_variables['os_name']
        configuration_file_path = configuration_filepath_os[host_os]
        current_configuration = host_manager.get_file_content(str(host), configuration_file_path)
        backup_configurations[str(host)] = current_configuration
    return backup_configurations


def restore_backup(host_manager, backup_configurations):
    for host in host_manager.get_group_hosts('all'):
        host_variables = host_manager.get_host_variables(host)
        host_os = host_variables['os_name']
        configuration_file_path = configuration_filepath_os[host_os]
        host_manager.modify_file_content(str(host), configuration_file_path, backup_configurations[str(host)])


def load_vulnerability_detector_configurations():
    return {
        'agent': load_configuration_template(configurations_paths['agent'], [{}], [{}]),
        'manager': load_configuration_template(configurations_paths['manager'], [{}], [{}])
    }


def configure_environment_manager(host_manager, configurations):
    def configure_host(host, host_configuration_role):
        host_os = host_manager.get_host_variables(host)['os_name']
        configuration_file_path = configuration_filepath_os[host_os]

        host_groups = host_manager.get_host_groups(host)
        host_configuration = None
        if 'manager' in host_groups:
            host_configuration = host_configuration_role['manager']
        elif 'agent' in host_groups:
            host_configuration = host_configuration_role['agent']

        current_configuration = host_manager.get_file_content(str(host), configuration_file_path)
        new_configuration = set_section_wazuh_conf(host_configuration[0].get('sections'), current_configuration.split("\n"))

        new_configuration = [line for line in new_configuration if line.strip() != ""]
        dom = xml.dom.minidom.parseString(''.join(new_configuration))
        new_configuration = "\n".join(dom.toprettyxml().split("\n")[1:])

        host_manager.modify_file_content(str(host), configuration_file_path, new_configuration)


    loader = DataLoader()
    configure_environment_parallel_map = [ (host, configurations) for host in host_manager.get_group_hosts('all')]

    with ThreadPool() as pool:
        pool.starmap(configure_host, configure_environment_parallel_map)


def control_environment(host_manager, operation, group_list):
    for group in group_list:
        for host in host_manager.get_group_hosts(group):
            host_manager.handle_wazuh_services(host, operation)


def get_event_regex(event, operation_data=None):
    """
    """
    regexes = {}
    with open(regex_path, 'r') as regex_file:
        regexes = yaml.load(regex_file, Loader=yaml.FullLoader)

    expected_event = regexes[event['event']]
    expected_regex = expected_event['regex']

    if 'parameters' in expected_event and not 'parameters' in event:
        raise Exception(f"Not provided enaugh data to create regex. Missing {event['PARAMETERS']}")
    elif 'parameters' in event:
        for parameter in expected_event['parameters']:
            expected_regex = expected_regex.replace(parameter, event['parameters'][parameter])


    return expected_regex


@pytest.fixture(scope='module')
def host_manager(request):
    inventory_path = request.config.getoption('--inventory-path')
    manager = HostManager(inventory_path)

    return manager

def truncate_agents_logs(host_manager):
    for agent in host_manager.get_group_hosts('agent'):
        host_os_name = host_manager.get_host_variables(agent)['os_name']
        host_manager.truncate_file(agent, logs_filepath_os[host_os_name])

def truncate_managers_logs(host_manager):
    for agent in host_manager.get_group_hosts('manager'):
        host_os_name = host_manager.get_host_variables(agent)['os_name']
        host_manager.truncate_file(agent, logs_filepath_os[host_os_name])

def truncate_logs(host_manager):
    # for manager in host_manager.get_group_hosts('manager'):
    #     host_manager.truncate_file(manager, '/var/ossec/logs/alerts/alerts.json')
    truncate_managers_logs(host_manager)
    truncate_agents_logs(host_manager)


def wait_until_vd_is_updated(host_manager):
    monitoring_data = {}
    for manager in host_manager.get_group_hosts('manager'):
        monitoring_data = generate_monitoring_logs_manager(host_manager, manager, 'Starting vulnerability scan', 600)

    monitoring_events(host_manager, monitoring_data)


def wait_until_vuln_scan_finished(host_manager):
    monitoring_data = {}
    for manager in host_manager.get_group_hosts('manager'):
        monitoring_data = generate_monitoring_logs_manager(host_manager, manager, 'Vulnerability scan finished.', 600)

    monitoring_events(host_manager, monitoring_data)


def launch_remote_operation(host, operation, operation_data, host_manager):
    print(f"Operation {operation} in {host} with {operation_data}")
    host_os_name = host_manager.get_host_variables(host)['os'].split('_')[0]
    host_os_arch = host_manager.get_host_variables(host)['arch']

    system = host_manager.get_host_variables(host)['os_name']
    if system == 'linux':
        system = host_manager.get_host_variables(host)['os'].split('_')[0]


    if operation == 'install_package':
        package_data = operation_data['package']
        package_url = package_data[host_os_name][host_os_arch]
        host_manager.install_package(host, package_url, system )
    elif operation == 'remove_package':
        package_data = operation_data['package']
        package_name = package_data[host_os_name]
        host_manager.remove_package(host, package_name, system)


def launch_remote_sequential_operation_on_agent(agent, task_list, host_manager):
    if task_list:
        for task in task_list:
            task_keys = list(task.keys())
            task_values = list(task.values())
            operation, operation_data = task_keys[0], task_values[0]
            launch_remote_operation(agent, operation, operation_data, host_manager)


def launch_parallel_operations(task_list, host_manager, group='agent'):
    agents = host_manager.get_group_hosts('agent')
    parallel_configuration = [(agent, task_list, host_manager) for agent in agents]
    with ThreadPool() as pool:
        # Use the pool to map the function to the list of hosts
        pool.starmap(launch_remote_sequential_operation_on_agent, parallel_configuration)


@pytest.fixture(scope='function')
def setup(preconditions, teardown, host_manager):
    host_manager = host_manager

    if preconditions:
        launch_parallel_operations(preconditions['tasks'], host_manager)

        if 'check_alerts' in preconditions:
            monitoring_data = {}

            for agent in host_manager.get_group_hosts('agent'):
                host_os_name = host_manager.get_host_variables(agent)['os'].split('_')[0]
                check_alerts_data = preconditions['check_alerts'][host_os_name]

                for event in check_alerts_data:
                    if not host_manager.get_host_variables(agent)['manager'] in monitoring_data:
                        monitoring_data[host_manager.get_host_variables(agent)['manager']] = []

                    if not 'parameters' in event:
                        event['parameters'] = {}
                    event['parameters']['HOST_NAME'] = agent

                    regex = get_event_regex(event)

                    monitoring_element = {
                        'regex': regex,
                        'path': '/var/ossec/logs/alerts/alerts.json',
                        'timeout': 30,
                        'parameters': event['parameters']
                    }
                    monitoring_data[host_manager.get_host_variables(agent)['manager']].append(monitoring_element)

            monitoring_data[host_manager.get_host_variables(agent)['manager']].append(monitoring_element)
            monitoring_events(host_manager, monitoring_data)

    yield

    if teardown:
        launch_parallel_operations(teardown, host_manager)

    for host in host_manager.get_group_hosts('manager'):
        host_manager.truncate_file(host, '/var/ossec/logs/alerts/alerts.json')


def create_temp_file(content):
    fd, temp_file_path = tempfile.mkstemp(text=True)  # 'text=True' specifies text mode
    with open(temp_file_path, 'w', newline='\n') as temp_file:
        temp_file.write(content)
    return temp_file_path


def monitoring_events(host_manager, monitoring_data):
    monitoring_file_content = ''
    results = {}

    for host, data in monitoring_data.items():
        monitoring_file_content += f"{host}:\n"
        for monitoring_event in data:
            monitoring_file_content += f"  - regex: '{monitoring_event['regex']}'\n"
            monitoring_file_content += f"    path: '{monitoring_event['path']}'\n"
            monitoring_file_content += f"    timeout: {monitoring_event['timeout']}\n"

        temp_file = create_temp_file(monitoring_file_content)
        try:
            results.update(HostMonitor(inventory_path=host_manager.get_inventory_path(), messages_path=temp_file, tmp_path=tmp_path).run())
        except TimeoutError:
            pass

        os.remove(temp_file)

    return results


def generate_monitoring_logs_all_agent(host_manager, regex_list, timeout_list):
    monitoring_data = {}
    for agent in host_manager.get_group_hosts('agent'):
        monitoring_data[agent] = []
        for index, regex_index in enumerate(regex_list):
            os_name = host_manager.get_host_variables(agent)['os_name']
            monitoring_data[agent].append({
                'regex': regex_index,
                'path': logs_filepath_os[os_name],
                'timeout': timeout_list[index]

            })

    print(monitoring_data)
    return monitoring_data


def generate_monitoring_logs_manager(host_manager, manager, regex, timeout):
    monitoring_data = {}
    os_name = host_manager.get_host_variables(manager)['os_name']
    monitoring_data[manager] = [{
        'regex': regex,
        'path': logs_filepath_os[os_name],
        'timeout': timeout

    }]

    return monitoring_data


def generate_monitoring_alerts_all_agent(host_manager, events_metadata):
    monitoring_data = {}

    for agent in host_manager.get_group_hosts('agent'):
        host_os_name = host_manager.get_host_variables(agent)['os'].split('_')[0]
        metadata_agent = events_metadata[host_os_name]

        if not host_manager.get_host_variables(agent)['manager'] in monitoring_data:
            monitoring_data[host_manager.get_host_variables(agent)['manager']] = []

        for event in metadata_agent[agent.get_host_variables(agent)['arch']]:
            event['parameters']['HOST_NAME'] = agent
            monitoring_element = {
                'regex': get_event_regex(event),
                'path': '/var/ossec/logs/alerts/alerts.json',
                'timeout': 120,
            }

            if 'parameters' in metadata_agent:
                monitoring_element['parameters'] = metadata_agent['parameters']

            monitoring_data[host_manager.get_host_variables(agent)['manager']].append(monitoring_element)


def get_master_ip(host_manager):
    for manager in host_manager.get_group_hosts('manager'):
        if host_manager.get_host_variables(manager)['type'] == 'master':
            return host_manager.get_host_variables(manager)['ip']


def get_state_index(host_manager):
    url = f"https://{get_master_ip(host_manager)}:9200/{STATE_INDEX_NAME}_search?"

    response = requests.get(url=url, params={'pretty': 'true'}, json=query, verify=False,
                            auth=requests.auth.HTTPBasicAuth(credentials['user'], credentials['password']))

    return response.text


def get_agents_id(host_manager):
    API_PROTOCOL = 'https'
    API_HOST = get_master_ip(host_manager)
    API_PORT = '55000'
    API_USER = 'wazuh'
    API_PASS = 'wazuh'
    API_LOGIN_ENDPOINT = '/security/user/authenticate'

    response_token = get_token_login_api(API_PROTOCOL, API_HOST, API_PORT, API_USER, API_PASS, API_LOGIN_ENDPOINT,
                                         timeout=10, login_attempts=3, sleep_time=1)

    agent_output = make_api_call(get_master_ip(host_manager), endpoint='/agents', token=response_token).json()
    agents_ids = {}
    for agent in agent_output['data']['affected_items']:
        agents_ids[agent['name']] = agent['id']

    return agents_ids


def get_agents_vulnerabilities(host_manager):
    API_PROTOCOL = 'https'
    API_HOST = get_master_ip(host_manager)
    API_PORT = '55000'
    API_USER = 'wazuh'
    API_PASS = 'wazuh'
    API_LOGIN_ENDPOINT = '/security/user/authenticate'

    response_token = get_token_login_api(API_PROTOCOL, API_HOST, API_PORT, API_USER, API_PASS, API_LOGIN_ENDPOINT,
                                         timeout=10, login_attempts=3, sleep_time=1)

    agents_ids = get_agents_id(host_manager)
    agents_vuln = {}
    for agent in host_manager.get_group_hosts('agent'):
        agents_vuln[agent] = make_api_call(get_master_ip(host_manager), endpoint=f"/vulnerability/{agents_ids[agent]}", token=response_token).json()['data']['affected_items']

    return agents_vuln

@pytest.mark.dependency()
def test_syscollector_initial_scans(host_manager):
    # The Agent's syscollector scan is run
    monitoring_data = generate_monitoring_logs_all_agent(host_manager,
                                                         [get_event_regex({'event': 'syscollector_scan_start'}),
                                                          get_event_regex({'event': 'syscollector_scan_end'})],
                                                          [20, 20])

    results = monitoring_events(host_manager, monitoring_data)

    assert all(results.values()), f"Expected message was not triggered for some agents, {results}"

    truncate_agents_logs(host_manager)

    wait_until_vuln_scan_finished(host_manager)

    # Check vulnerabilities for agent
    agents_vuln_before_second_scan = get_agents_vulnerabilities(host_manager)
    for agent, vuln in agents_vuln_before_second_scan.items():
        assert vuln, f"No vulnerabilities were detected for agent {agent}"

    # Check Agent's System states are stored
    state_index_content_before_second_scan = get_state_index(host_manager)

    # Compare agents_vuln_before_second_scan with state_index_content
    # To Do

    # The Agent's syscollector scan is run
    monitoring_data = generate_monitoring_logs_all_agent(host_manager,
                                                         [get_event_regex({'event': 'syscollector_scan_start'}),
                                                          get_event_regex({'event': 'syscollector_scan_end'})],
                                                          [60, 60])

    results = monitoring_events(host_manager, monitoring_data)

    assert all(results.values()), f"Expected message was not triggered for some agents, {results}"

    truncate_managers_logs(host_manager)

    wait_until_vuln_scan_finished(host_manager)

    agents_vuln_after_second_scan = get_agents_vulnerabilities(host_manager)


    assert agents_vuln_before_second_scan == agents_vuln_after_second_scan

    # Check Agent's System states are stored
    state_index_content_after_second_scan = get_state_index(host_manager)

    assert state_index_content_after_second_scan == state_index_content_before_second_scan


# @pytest.mark.dependency(depends=["test_syscollector_second_scan"])
@pytest.mark.parametrize('preconditions, body, teardown', complete_list, ids=list_ids)
def test_vulnerability_detector_scans(preconditions, body, teardown, setup, host_manager):
    # Launch tests tasks
    launch_parallel_operations(body['tasks'], host_manager)

    # Check vulnerability
    agents_vuln_after_second_scan = get_agents_vulnerabilities(host_manager)

    # Check alert in Wazuh Indexer
    # monitoring_data = generate_monitoring_alerts_all_agent(host_manager, body['check_alerts'])
    expected_alerts = body['check_agent_alert_indexer']

    # Check agent System state

    results = monitoring_events(host_manager, monitoring_data)
    assert all(results.values()), f"Expected message was not triggered for some agents, {results}"
