import pytest
import os
import pytest
import os
import subprocess
import argparse
import ansible_runner
import base64
import re
from multiprocessing.pool import ThreadPool
from wazuh_testing.tools.configuration import (
    load_configuration_template, set_section_wazuh_conf
)
import xml.dom.minidom
import yaml
import tempfile

from wazuh_testing.tools.system import HostManager
from ansible.inventory.manager import InventoryManager
from ansible.parsing.dataloader import DataLoader
from wazuh_testing.tools.monitoring import HostMonitor


current_dir = os.path.dirname(__file__)
configurations_dir = os.path.join(current_dir, "data", "configurations")
cases = {}
local_path = os.path.dirname(os.path.abspath(__file__))
tmp_path = os.path.join(local_path, 'tmp')
regex_path = os.path.join(current_dir, 'data', 'regex.yaml')


with open(os.path.join(current_dir, 'cases.yaml'), 'r') as cases_file:
    cases = yaml.load(cases_file, Loader=yaml.FullLoader)


packages_manager = {
    'centos': 'yum',
    'ubuntu': 'apt'
}

configurations_paths = {
    'manager': os.path.join(configurations_dir, 'manager.yaml'),
    'agent': os.path.join(configurations_dir, 'agent.yaml')
}

configuration_filepath_os = {
    'linux': '/var/ossec/etc/ossec.conf',
    'windows': 'C:\Program Files (x86)\ossec-agent\ossec.conf',
    'macos': '/Library/Ossec/etc/ossec.conf'
}
logs_filepath_os = {
    'linux': '/var/ossec/logs/ossec.log',
    'windows': 'C:\Program Files (x86)\ossec-agent\ossec.log',
    'macos': '/Library/Ossec/logs/ossec.log'
}


def get_event_regex(event, operation_data=None):
    regexes = {}
    with open(regex_path, 'r') as regex_file:
        regexes = yaml.load(regex_file, Loader=yaml.FullLoader)

    expected_event = regexes[event['event']]
    expected_regex = expected_event['regex']

    if 'parameters' in expected_event and not 'parameters' in event:
        raise Exception(f"Not provided enaugh data to create regex. Missing {event['PARAMETERS']}")
    elif 'parameters' in event:
        for parameter in expected_event['parameters']:
            expected_regex = expected_regex.replace(parameter, event['parameters'][parameter])


    return expected_regex

@pytest.fixture(scope='module')
def get_host_manager(request):
    inventory_path = request.config.getoption('--inventory-path')
    host_manager = HostManager(inventory_path)

    return host_manager, inventory_path


@pytest.fixture(scope='module')
def restart_environment(get_host_manager):
    host_manager, inventory = get_host_manager
    for host in host_manager.get_group_hosts('manager'):
        host_manager.handle_wazuh_services(host, 'restart')

    for host in host_manager.get_group_hosts('agent'):
        host_manager.handle_wazuh_services(host, 'restart')


@pytest.fixture(scope='module', autouse=False)
def configure_environment_manager(get_host_manager):
    def configure_host(host):
        host_variables = host.get_vars()
        host_os = host_variables['os_name']
        configuration_file_path = configuration_filepath_os[host_os]


        host_configuration = None
        host_groups = [str(group) for group in host.get_groups()]
        if 'manager' in host_groups:
            host_configuration = configurations_paths['manager']
        elif 'agent' in host_groups:
            host_configuration = configurations_paths['agent']

        current_configuration = host_manager.get_file_content(str(host), configuration_file_path)
        backup_configurations[host] = current_configuration
        new_configuration_template = load_configuration_template(host_configuration, [{}], [{}])
        new_configuration = set_section_wazuh_conf(new_configuration_template[0].get('sections'), current_configuration.split("\n"))
        new_configuration = [line for line in new_configuration if line.strip() != ""]
        dom = xml.dom.minidom.parseString(''.join(new_configuration))
        new_configuration = "\n".join(dom.toprettyxml().split("\n")[1:])

        host_manager.modify_file_content(str(host), configuration_file_path, new_configuration)

    backup_configurations = {}


    host_manager, inventory  = get_host_manager


    loader = DataLoader()
    inventory_manager = InventoryManager(loader=loader, sources=inventory)
    all_hosts = inventory_manager.get_hosts()


    with ThreadPool() as pool:
        pool.map(configure_host, all_hosts)

    yield

    for host in all_hosts:
        host_variables = host.get_vars()
        host_os = host_variables['os_name']
        configuration_file_path = configuration_filepath_os[host_os]

        host_manager.modify_file_content(str(host), configuration_file_path, backup_configurations[host])

complete_list = [ (case['preconditions'], case['body'], case['teardown']) for case in cases]
list_ids = [ case['id'] for case in cases]


def launch_remote_operation(host, operation, operation_data, hm, inventory):
    print(f"Operation {operation} in {host} with {operation_data}")
    host_os_name = hm.get_host_variables(host)['os'].split('_')[0]
    host_os_arch = hm.get_host_variables(host)['arch']
    if operation == 'install_package':
        package_data = operation_data['package']
        package_url = package_data[host_os_name][host_os_arch]
        package_manager = packages_manager[host_os_name]
        print(f"Install package {host} {package_url} {package_manager}")
        hm.install_package(host, package_url, package_manager )
    elif operation == 'remove_package':
        package_data = operation_data['package']
        package_name = package_data[host_os_name]
        package_manager = packages_manager[host_os_name]
        hm.remove_package(host, package_name, package_manager )


def launch_remote_sequential_operation_on_agent(agent, task_list, host_manager, inventory):
    if task_list:
        for task in task_list:
            task_keys = list(task.keys())
            task_values = list(task.values())
            operation, operation_data = task_keys[0], task_values[0]
            launch_remote_operation(agent, operation, operation_data, host_manager, inventory)


def launch_parallel_operations(task_list, host_manager, inventory, group='agent'):
    agents = host_manager.get_group_hosts('agent')
    parallel_configuration = [(agent, task_list, host_manager, inventory) for agent in agents]
    with ThreadPool() as pool:
        # Use the pool to map the function to the list of hosts
        pool.starmap(launch_remote_sequential_operation_on_agent, parallel_configuration)


@pytest.fixture(scope='function')
def setup(preconditions, teardown, get_host_manager):
    hm, inventory = get_host_manager

    if preconditions:
        launch_parallel_operations(preconditions['tasks'], hm, inventory)

        if 'check_alerts' in preconditions:
            monitoring_data = {}

            for agent in hm.get_group_hosts('agent'):
                host_os_name = hm.get_host_variables(agent)['os'].split('_')[0]
                check_alerts_data = preconditions['check_alerts'][host_os_name]
                for event in check_alerts_data:
                    if not hm.get_host_variables(agent)['manager'] in monitoring_data:
                        monitoring_data[hm.get_host_variables(agent)['manager']] = []
                        check_alerts_data['parameters']['HOST_NAME'] = agent

                regex = get_event_regex(preconditions['check_alerts'][host_os_name])
                monitoring_data[hm.get_host_variables('manager')] = [{
                    'regex': regex,
                    'path': '/var/ossec/logs/alerts/alerts.json',
                    'timeout': 30
                }]


    for agent in hm.get_group_hosts('agent'):
        host_os_name = hm.get_host_variables(agent)['os'].split('_')[0]

        for event in metadata_agent:
            event['parameters']['HOST_NAME'] = agent
            monitoring_element = {
                'regex': get_event_regex(event),
                'path': '/var/ossec/logs/alerts/alerts.json',
                'timeout': 120
            }

            if 'parameters' in metadata_agent:
                monitoring_element['parameters'] = metadata_agent['parameters']

            monitoring_data[hm.get_host_variables(agent)['manager']].append(monitoring_element)






            monitoring_events(get_host_manager, monitoring_data)

    yield

    if teardown:
        launch_parallel_operations(teardown, hm, inventory)

    # for host in hm.get_group_hosts('manager'):
    #     hm.modify_file_content(host, path='/var/ossec/logs/alerts/alerts.json', content='')


def create_temp_file(content):
    fd, temp_file_path = tempfile.mkstemp(text=True)  # 'text=True' specifies text mode
    with open(temp_file_path, 'w', newline='\n') as temp_file:
        temp_file.write(content)
    return temp_file_path


def monitoring_events(get_host_manager, monitoring_data):
    hm, inventory = get_host_manager
    monitoring_file_content = ''

    for host, data in monitoring_data.items():
        monitoring_file_content += f"{host}:\n"
        for monitoring_event in data:
            monitoring_file_content += f"  - regex: '{monitoring_event['regex']}'\n"
            monitoring_file_content += f"    path: '{monitoring_event['path']}'\n"
            monitoring_file_content += f"    timeout: {monitoring_event['timeout']}\n"

    temp_file = create_temp_file(monitoring_file_content)

    HostMonitor(inventory_path=inventory, messages_path=temp_file, tmp_path=tmp_path).run()

    os.remove(temp_file)


@pytest.mark.dependency()
def test_syscollector_first_scan(get_host_manager):
    """
    """
    hm, inventory = get_host_manager
    regex_info = {
        'event': 'syscollector_first_scan_start'
    }

    monitoring_data = {}
    regex = get_event_regex(regex_info)
    for agent in hm.get_group_hosts('agent'):
        host_os_name = hm.get_host_variables(agent)['os'].split('_')[0]
        monitoring_data[agent] = [{
            'regex': regex,
            'path': logs_filepath_os['linux'],
            'timeout': 120
        }]

    monitoring_events(get_host_manager, monitoring_data)


@pytest.mark.dependency(depends=["test_syscollector_first_scan"])
def test_syscollector_second_scan(get_host_manager):
    """
    """
    hm, inventory = get_host_manager
    monitoring_data = {}
    regex_info = {
        'event': 'syscollector_first_scan_start'
    }
    regex = get_event_regex(regex_info)
    for agent in hm.get_group_hosts('agent'):
        host_os_name = hm.get_host_variables(agent)['os'].split('_')[0]
        monitoring_data[agent] = [{
            'regex': regex,
            'path': logs_filepath_os['linux'],
            'timeout': 120
        }]

    monitoring_events(get_host_manager, monitoring_data)


# @pytest.mark.dependency(depends=["test_syscollector_second_scan"])
@pytest.mark.parametrize('preconditions, body, teardown', complete_list, ids=list_ids)
def test_vulnerability_detector_scans(preconditions, body, teardown, setup, get_host_manager):
    """
    """
    hm, inventory = get_host_manager
    launch_parallel_operations(body['tasks'], hm, inventory)
    metadata = body['check_alerts']
    monitoring_data = {}
    for agent in hm.get_group_hosts('agent'):
        host_os_name = hm.get_host_variables(agent)['os'].split('_')[0]
        metadata_agent = metadata[host_os_name]
        if not hm.get_host_variables(agent)['manager'] in monitoring_data:
            monitoring_data[hm.get_host_variables(agent)['manager']] = []

        for event in metadata_agent:
            event['parameters']['HOST_NAME'] = agent
            monitoring_element = {
                'regex': get_event_regex(event),
                'path': '/var/ossec/logs/alerts/alerts.json',
                'timeout': 120
            }

            if 'parameters' in metadata_agent:
                monitoring_element['parameters'] = metadata_agent['parameters']

            monitoring_data[hm.get_host_variables(agent)['manager']].append(monitoring_element)


    print(monitoring_data)



    monitoring_events(get_host_manager, monitoring_data)
